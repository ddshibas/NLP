{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source_kw</th>\n",
       "      <th>key_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В Беларуси предъявили новое обвинение россияни...</td>\n",
       "      <td>общество, беларусь, уголовное дело, егор дудни...</td>\n",
       "      <td>арест, уголовное дело, беларусь, фильм, актер,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>В Калининградской области с 8 ноября до 1 февр...</td>\n",
       "      <td>калининградская область, коронавирус, QR коды</td>\n",
       "      <td>коронавирус, калининградская область, ограниче...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Южноафриканский писатель Дэймон Гэлгут стал об...</td>\n",
       "      <td>премия, букер</td>\n",
       "      <td>писатель, букеровская премия, литература, роман,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>В 97-этажной башне «Федерация» в Москве-Сити к...</td>\n",
       "      <td>криптовалюты, обмен, отмывание денег, bloomber...</td>\n",
       "      <td>киберпреступники, криптовалюта, москва сити, о...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Полиция Латвии в рамках своего расследования «...</td>\n",
       "      <td>дело магнитского, латвия</td>\n",
       "      <td>латвия, магнитский, дело магнитского, недвижим...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  В Беларуси предъявили новое обвинение россияни...   \n",
       "1  В Калининградской области с 8 ноября до 1 февр...   \n",
       "2  Южноафриканский писатель Дэймон Гэлгут стал об...   \n",
       "3  В 97-этажной башне «Федерация» в Москве-Сити к...   \n",
       "4  Полиция Латвии в рамках своего расследования «...   \n",
       "\n",
       "                                           source_kw  \\\n",
       "0  общество, беларусь, уголовное дело, егор дудни...   \n",
       "1      калининградская область, коронавирус, QR коды   \n",
       "2                                      премия, букер   \n",
       "3  криптовалюты, обмен, отмывание денег, bloomber...   \n",
       "4                           дело магнитского, латвия   \n",
       "\n",
       "                                           key_words  \n",
       "0  арест, уголовное дело, беларусь, фильм, актер,...  \n",
       "1  коронавирус, калининградская область, ограниче...  \n",
       "2   писатель, букеровская премия, литература, роман,  \n",
       "3  киберпреступники, криптовалюта, москва сити, о...  \n",
       "4  латвия, магнитский, дело магнитского, недвижим...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('kw.csv', delimiter='|')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все источники взяты с сайта https://novayagazeta.ru/news. В источнике ключевые слова сделаны метками с хештегом под каждой новостью. Метки кликабельные и отображают новости с этой же меткой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Дарья\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import RAKE\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_intersection = 0\n",
    "count_non_intersection = 0\n",
    "for i in range(df.shape[0]):\n",
    "    for key_w in df.loc[i][\"key_words\"].split(\"\\n\"):\n",
    "        if key_w in df.loc[i][\"source_kw\"].split(\"\\n\"):\n",
    "            count_intersection += 1\n",
    "        else:\n",
    "            count_non_intersection += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "пересечение:  0\n",
      "непересечение:  13\n",
      "процент пересечений:  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"пересечение: \", count_intersection)\n",
    "print(\"непересечение: \", count_non_intersection)\n",
    "print(\"процент пересечений: \", round(count_intersection / (count_intersection + count_non_intersection), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(пересечения посчитаны неверно)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard = [[], [], [], [], []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-b2a28893078b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mwords_to_add\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mwords_to_add\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mstandard\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords_to_add\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    words = df[\"source_kw\"].tolist()\n",
    "    my_words = df[\"key_words\"].tolist()\n",
    "    words_to_add = []\n",
    "    words_to_add.extend(words[i].split(\"\\n\"))\n",
    "    words_to_add.extend(my_words[i].split(\"\\n\"))\n",
    "    standard[i].append(set(words_to_add))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rake ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rake = RAKE.Rake(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[0, \"rake_key_words\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    rake_pairs = rake.run(df.loc[i][\"text\"], maxWords=3, minFrequency=2)\n",
    "    rake_kw = \"\"\n",
    "    for pair in rake_pairs:\n",
    "        rake_kw = rake_kw + pair[0] + \"\\n\"\n",
    "    df.at[i, \"rake_key_words\"] = rake_kw[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextRank ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization import keywords as kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[0, \"TRank_key_words\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    df.at[i, \"TRank_key_words\"] = kw(df.loc[i][\"text\"], pos_filter=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## td-idf ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[0, \"tfidf_key_words\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"text\"]\n",
    "tfidf = tfidf_vectorizer.fit_transform(texts)\n",
    "names = tfidf_vectorizer.get_feature_names()\n",
    "data = tfidf.todense().tolist()\n",
    "tfidf_df = pd.DataFrame(data, columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = tfidf_df[filter(lambda x: x not in stop , tfidf_df.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tfidf_df.iterrows():\n",
    "    tfidf_keys = i[1].sort_values(ascending=False)[:20].index.tolist()\n",
    "    tfidf_s = \"\"\n",
    "    for key in tfidf_keys:\n",
    "        tfidf_s = tfidf_s + key + \"\\n\"\n",
    "    df.at[i[0], \"tfidf_key_words\"] = tfidf_s[:-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
